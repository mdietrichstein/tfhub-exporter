{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example - MobileNet V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents how to use the `tfhub-exporter`script to export and use an optimized version of the MobileNet classifier available at https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/3.\n",
    "\n",
    "First visit https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/3 and grab the module url, e.g. by using the `Copy URL` button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODULE_URL = 'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspect the module inputs and outputs\n",
    "The following command downloads the module data and displays all available inputs and outputs with the corresponding details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0521 16:35:10.462617 4347246016 main.py:47] Loading module \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/3\"\n",
      "I0521 16:35:10.477555 4347246016 resolver.py:79] Using /var/folders/nw/pc9xb0fx7m99qv22qgl8sm6c0000gn/T/tfhub_modules to cache modules.\n",
      "I0521 16:35:19.260080 4347246016 main.py:24] <Took 8.80s>\n",
      "\n",
      " Model Inputs\n",
      "╭────────┬─────────────────────┬─────────╮\n",
      "│  name  │        shape        │  dtype  │\n",
      "├────────┼─────────────────────┼─────────┤\n",
      "│ images │ (None, 224, 224, 3) │ float32 │\n",
      "╰────────┴─────────────────────┴─────────╯\n",
      "\n",
      " Supported Outputs\n",
      "╭───────────┬──────────────┬─────────╮\n",
      "│ signature │    shape     │  dtype  │\n",
      "├───────────┼──────────────┼─────────┤\n",
      "│  default  │ (None, 1001) │ float32 │\n",
      "╰───────────┴──────────────┴─────────╯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main.py show-info $MODULE_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export the module\n",
    "\n",
    "The next command loads the MobileNet model, freezes the network weights and applies a number of optimizations in order to reduce the file size as well as model loading time. The final model is saved in `./mobilenetV2/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_TARGET_DIR = './mobilenetV2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to delete the target directory first in case it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $EXPORT_TARGET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0521 16:37:02.648819 4591490496 main.py:89] Loading module \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/3\"\n",
      "I0521 16:37:02.651168 4591490496 resolver.py:79] Using /var/folders/nw/pc9xb0fx7m99qv22qgl8sm6c0000gn/T/tfhub_modules to cache modules.\n",
      "I0521 16:37:10.420182 4591490496 main.py:24] <Took 7.77s>\n",
      "I0521 16:37:10.420423 4591490496 main.py:97] Detected inputs \"{'images': <tf.Tensor 'images:0' shape=(?, 224, 224, 3) dtype=float32>}\"\n",
      "I0521 16:37:10.420545 4591490496 main.py:98] Output \"module_apply_default/MobilenetV2/Logits/output:0\": \"{'default': <hub.ParsedTensorInfo shape=(?, 1001) dtype=float32 is_sparse=False>}\"\n",
      "I0521 16:37:10.420630 4591490496 main.py:102] Normalized output name: \"module_apply_default/MobilenetV2/Logits/output\"\n",
      "I0521 16:37:12.957731 4591490496 main.py:110] Exporting TF Hub module to \"/var/folders/nw/pc9xb0fx7m99qv22qgl8sm6c0000gn/T/tmpfa7rdsv_/./mobilenetV2\"\n",
      "I0521 16:37:18.612892 4591490496 main.py:24] <Took 5.65s>\n",
      "I0521 16:37:18.613455 4591490496 main.py:118] Freezing Graph\n",
      "I0521 16:37:30.746839 4591490496 main.py:24] <Took 17.79s>\n",
      "I0521 16:37:30.747103 4591490496 main.py:125] Applying transforms ('remove_nodes(op=Identity)', 'merge_duplicate_nodes', 'strip_unused_nodes', 'fold_constants(ignore_errors=true)', 'fold_batch_norms').\n",
      "Logs at \"/var/folders/nw/pc9xb0fx7m99qv22qgl8sm6c0000gn/T/tmpfa7rdsv_/log\"\n",
      "I0521 16:37:32.856378 4591490496 main.py:24] <Took 19.90s>\n",
      "I0521 16:37:32.856548 4591490496 main.py:130] Exporting SavedModel to \"./mobilenetV2\"\n",
      "I0521 16:37:34.198616 4591490496 main.py:24] <Took 21.24s>\n",
      "\n",
      "\n",
      "EXPORT SUMMARY\n",
      "\n",
      "Export Location: \"/Users/marc/Development/tfhub-exporter/mobilenetV2\"\n",
      "\n",
      " Model Inputs\n",
      "╭────────┬─────────────────────┬─────────╮\n",
      "│  name  │        shape        │  dtype  │\n",
      "├────────┼─────────────────────┼─────────┤\n",
      "│ images │ (None, 224, 224, 3) │ float32 │\n",
      "╰────────┴─────────────────────┴─────────╯\n",
      "\n",
      " Model Outputs for signature \"default\"\n",
      "╭──────────────────────────────────────────────────┬──────────────┬─────────╮\n",
      "│                       name                       │    shape     │  dtype  │\n",
      "├──────────────────────────────────────────────────┼──────────────┼─────────┤\n",
      "│ module_apply_default/MobilenetV2/Logits/output:0 │ (None, 1001) │ float32 │\n",
      "╰──────────────────────────────────────────────────┴──────────────┴─────────╯\n"
     ]
    }
   ],
   "source": [
    "!python main.py export $MODULE_URL $EXPORT_TARGET_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the exported and optimized model\n",
    "\n",
    "Next, we want to load the optimized model and find out what the following image is classified as.\n",
    "![Test Image](example.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-53180f8271f8>:6: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
      "WARNING:tensorflow:From /Users/marc/miniconda2/envs/placeholderai/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Most probable class: 152\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.saved_model import tag_constants\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    metagraph = tf.saved_model.loader.load(sess, [tag_constants.SERVING], EXPORT_TARGET_DIR)\n",
    "    \n",
    "    input_mappings = metagraph.signature_def['serving_default'].inputs\n",
    "    output_mappings = metagraph.signature_def['serving_default'].outputs\n",
    "    \n",
    "    # We know the input names from either the 'show-info' command, or the 'Module Inputs' information\n",
    "    # displayed at the end of the 'export' command\n",
    "    input_images = sess.graph.get_tensor_by_name(input_mappings['images'].name)\n",
    "    \n",
    "    # The output tensor information is always exported under the name 'output'\n",
    "    output = sess.graph.get_tensor_by_name(output_mappings['output'].name)\n",
    "    \n",
    "    # Load the example image the tensorflow way\n",
    "    file_reader = tf.read_file('example.jpg')\n",
    "    example = tf.image.decode_jpeg(file_reader)\n",
    "    images = tf.expand_dims(example, 0)\n",
    "    images = tf.image.resize_image_with_crop_or_pad(images, 224, 224)\n",
    "    \n",
    "    # See https://www.tensorflow.org/hub/common_signatures/images#input\n",
    "    images = tf.image.convert_image_dtype(images, tf.float32)\n",
    "\n",
    "    # Load image\n",
    "    images = sess.run(images)\n",
    "    \n",
    "    # Run classifier on image\n",
    "    result = sess.run(output, feed_dict={\n",
    "        input_images: images\n",
    "    })\n",
    "    \n",
    "    # Find class with highest probability\n",
    "    classifications = result[0]\n",
    "    most_probable_class = np.argmax(classifications)\n",
    "    print(f'Most probable class: {most_probable_class}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the most probable class is **152**. Lets find out what the corresponding label is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Chihuahua\\n'\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "data = urllib.request.urlopen('https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "lines = list([str(line) for line in data])\n",
    "\n",
    "print(lines[most_probable_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, **Chihuahua** sounds about right. Looks like our exported model is working as expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
